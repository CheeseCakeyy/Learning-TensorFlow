{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Discription:\nThis notebook implements a Convolutional Neural Network (ConvNet) on the MNIST dataset as demonstrated in the book “Deep Learning with Python.” The code has been reproduced and executed here solely for learning and educational purposes. All original concepts and code logic belong to the book and its author, and this notebook serves only as a personal practice implementation.","metadata":{}},{"cell_type":"markdown","source":"## Building a simple convnet:","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # 0 = hide all, 1 = hide INFO, 2 = hide WARNING, 3 = hide ERROR\n#The above piece of code is to hide the warnings ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T14:04:38.356204Z","iopub.execute_input":"2026-02-06T14:04:38.356737Z","iopub.status.idle":"2026-02-06T14:04:38.360236Z","shell.execute_reply.started":"2026-02-06T14:04:38.356709Z","shell.execute_reply":"2026-02-06T14:04:38.359437Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\ninputs = keras.Input(shape=(28,28,1),name='input_layer') #since out images have length and width of 28 pixals and color channels=1 since the images in MNIST are in grayscale\nx = layers.Conv2D(filters=32, kernel_size=3, activation='relu') (inputs)\nx = layers.MaxPooling2D(pool_size=2) (x)\nx = layers.Conv2D(filters=64, kernel_size=3, activation='relu') (x)\nx = layers.MaxPooling2D(pool_size=2) (x)\nx = layers.Conv2D(filters=128, kernel_size=3, activation='relu') (x)\nx = layers.Flatten() (x)\noutputs = layers.Dense(10, activation='softmax', name='output_layer') (x)\n\nmodel = keras.Model(inputs=inputs, outputs=outputs, name='ConvNet_1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T14:04:38.361827Z","iopub.execute_input":"2026-02-06T14:04:38.362071Z","iopub.status.idle":"2026-02-06T14:04:38.409149Z","shell.execute_reply.started":"2026-02-06T14:04:38.362038Z","shell.execute_reply":"2026-02-06T14:04:38.408606Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#Summerizing the model\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T14:04:38.409870Z","iopub.execute_input":"2026-02-06T14:04:38.410135Z","iopub.status.idle":"2026-02-06T14:04:38.426093Z","shell.execute_reply.started":"2026-02-06T14:04:38.410114Z","shell.execute_reply":"2026-02-06T14:04:38.425427Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"ConvNet_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ConvNet_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │        \u001b[38;5;34m11,530\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,530</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,202\u001b[0m (407.04 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,202</span> (407.04 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"*  Output of every Conv2D and MaxPooling2D layer is a rank-3 tensor of shape (height, width, channels).\n*  The width and height dimensions tend to shrink as we go deeper in the model.\n*  The first argument that is 'filters' controls the number of channels in the output of Conv2D layer.\n\nAfter the last Conv2D layer we have an output tensor of shape (3,3,128) but we had to feed it to our output layer which is a Densly connected layer, these layers process inputs which are 1D while we had a 3D input for it, so we flatten the 3D outputs to 1D using a *Flatten* layer, before passing it to the dense layer.\n\nLastly a 10 way classification was done in teh output layer via a *Softmax* activation since we have 10 digit classes in the MNIST dataset.","metadata":{}},{"cell_type":"markdown","source":"## Compiling and training the model on MNIST:\nThe dataset consists of 60000 training samples and 10000 test samples","metadata":{}},{"cell_type":"code","source":"#Importing the dataset\nfrom tensorflow.keras.datasets import mnist\n(train_imgs,train_labels),(test_imgs,test_labels) = mnist.load_data()\n\n#Scaling and reshaping the data\ntrain_imgs = train_imgs.reshape(60000,28,28,1)\ntrain_imgs = train_imgs.astype('float32') / 255\n\ntest_imgs = test_imgs.reshape(10000,28,28,1)\ntest_imgs = test_imgs.astype('float32') / 255","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T14:04:38.427300Z","iopub.execute_input":"2026-02-06T14:04:38.427667Z","iopub.status.idle":"2026-02-06T14:04:38.818388Z","shell.execute_reply.started":"2026-02-06T14:04:38.427646Z","shell.execute_reply":"2026-02-06T14:04:38.817808Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#compiling and training the model\nmodel.compile(optimizer='rmsprop',\n             loss='sparse_categorical_crossentropy',\n             metrics=['accuracy'])\n\nmodel.fit(train_imgs, train_labels, epochs=5, batch_size=64) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T14:04:38.819408Z","iopub.execute_input":"2026-02-06T14:04:38.819725Z","iopub.status.idle":"2026-02-06T14:04:55.062120Z","shell.execute_reply.started":"2026-02-06T14:04:38.819691Z","shell.execute_reply":"2026-02-06T14:04:55.061471Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.3697\nEpoch 2/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0463\nEpoch 3/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0285\nEpoch 4/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0226\nEpoch 5/5\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0170\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d4b840bffb0>"},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## Evalutating/testing the model on testdata:","metadata":{}},{"cell_type":"code","source":"test_loss, test_acc = model.evaluate(test_imgs, test_labels)\nprint(f\"Test accuracy: {test_acc}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-06T14:04:55.063002Z","iopub.execute_input":"2026-02-06T14:04:55.063283Z","iopub.status.idle":"2026-02-06T14:04:56.811670Z","shell.execute_reply.started":"2026-02-06T14:04:55.063253Z","shell.execute_reply":"2026-02-06T14:04:56.810884Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0361\nTest accuracy: 0.9921000003814697\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"The model achived astonishing **99.21%** accuracy on the test data, it proves that convnets are much better than a model with only Densly connected layers at compute vision tasks.","metadata":{}}]}